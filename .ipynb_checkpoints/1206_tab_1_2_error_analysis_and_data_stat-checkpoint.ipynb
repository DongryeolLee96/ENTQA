{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f530145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a03a594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nq_dir='/home/donaldo9603/workspace/numeric/gptexpansion/out/49754/NQ_eval.json'\n",
    "tq_dir='/home/donaldo9603/workspace/numeric/gptexpansion/out/49755/TQ_eval.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e8e13dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(nq_dir) as f:\n",
    "    nq=json.load(f)\n",
    "with open(tq_dir) as f:\n",
    "    tq=json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1088d0",
   "metadata": {},
   "source": [
    "### NQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51b5d35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_set=defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f48914eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in nq:\n",
    "    if d['ans_type'] in others:\n",
    "        ent_set['others'].append(d)\n",
    "    else:\n",
    "        ent_set[d['ans_type']].append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d19f4316",
   "metadata": {},
   "outputs": [],
   "source": [
    "others=['NORP', 'LOC','WORK_OF_ART','FAC','PRODUCT','EVENT','LAW','LANGUAGE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23f47757",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods=['golden_answer', 'fb', 'inst_expand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e16762ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result using:  golden_answer\n",
      "Average on 1035 data in PERSON type\n",
      "Methods: golden_answer, entity_type: PERSON\n",
      "Average number of annotation: 1.951\n",
      "\n",
      "Average on 586 data in unknown type\n",
      "Methods: golden_answer, entity_type: unknown\n",
      "Average number of annotation: 1.691\n",
      "\n",
      "Average on 169 data in CARDINAL type\n",
      "Methods: golden_answer, entity_type: CARDINAL\n",
      "Average number of annotation: 1.633\n",
      "\n",
      "Average on 185 data in others type\n",
      "Methods: golden_answer, entity_type: others\n",
      "Average number of annotation: 1.773\n",
      "\n",
      "Average on 288 data in GPE type\n",
      "Methods: golden_answer, entity_type: GPE\n",
      "Average number of annotation: 2.160\n",
      "\n",
      "Average on 198 data in ORG type\n",
      "Methods: golden_answer, entity_type: ORG\n",
      "Average number of annotation: 1.970\n",
      "\n",
      "Average on 499 data in DATE type\n",
      "Methods: golden_answer, entity_type: DATE\n",
      "Average number of annotation: 1.723\n",
      "\n",
      "Average on 13 data in ORDINAL type\n",
      "Methods: golden_answer, entity_type: ORDINAL\n",
      "Average number of annotation: 2.154\n",
      "\n",
      "Average on 19 data in QUANTITY type\n",
      "Methods: golden_answer, entity_type: QUANTITY\n",
      "Average number of annotation: 1.842\n",
      "\n",
      "Average on 11 data in MONEY type\n",
      "Methods: golden_answer, entity_type: MONEY\n",
      "Average number of annotation: 1.273\n",
      "\n",
      "Average on 10 data in PERCENT type\n",
      "Methods: golden_answer, entity_type: PERCENT\n",
      "Average number of annotation: 1.400\n",
      "\n",
      "Average on 7 data in TIME type\n",
      "Methods: golden_answer, entity_type: TIME\n",
      "Average number of annotation: 1.143\n",
      "\n",
      "Result using methods golden_answer\n",
      "1.849337748344371\n",
      "\n",
      "--------------------\n",
      "Result using:  fb\n",
      "Average on 1035 data in PERSON type\n",
      "Methods: fb, entity_type: PERSON\n",
      "Average number of annotation: 13.386\n",
      "\n",
      "Average on 586 data in unknown type\n",
      "Methods: fb, entity_type: unknown\n",
      "Average number of annotation: 14.857\n",
      "\n",
      "Average on 169 data in CARDINAL type\n",
      "Methods: fb, entity_type: CARDINAL\n",
      "Average number of annotation: 26.633\n",
      "\n",
      "Average on 185 data in others type\n",
      "Methods: fb, entity_type: others\n",
      "Average number of annotation: 9.832\n",
      "\n",
      "Average on 288 data in GPE type\n",
      "Methods: fb, entity_type: GPE\n",
      "Average number of annotation: 32.510\n",
      "\n",
      "Average on 198 data in ORG type\n",
      "Methods: fb, entity_type: ORG\n",
      "Average number of annotation: 11.778\n",
      "\n",
      "Average on 499 data in DATE type\n",
      "Methods: fb, entity_type: DATE\n",
      "Average number of annotation: 4.220\n",
      "\n",
      "Average on 13 data in ORDINAL type\n",
      "Methods: fb, entity_type: ORDINAL\n",
      "Average number of annotation: 6.308\n",
      "\n",
      "Average on 19 data in QUANTITY type\n",
      "Methods: fb, entity_type: QUANTITY\n",
      "Average number of annotation: 2.526\n",
      "\n",
      "Average on 11 data in MONEY type\n",
      "Methods: fb, entity_type: MONEY\n",
      "Average number of annotation: 10.182\n",
      "\n",
      "Average on 10 data in PERCENT type\n",
      "Methods: fb, entity_type: PERCENT\n",
      "Average number of annotation: 24.500\n",
      "\n",
      "Average on 7 data in TIME type\n",
      "Methods: fb, entity_type: TIME\n",
      "Average number of annotation: 9.143\n",
      "\n",
      "Result using methods fb\n",
      "14.315562913907284\n",
      "\n",
      "--------------------\n",
      "Result using:  inst_expand\n",
      "Average on 1035 data in PERSON type\n",
      "Methods: inst_expand, entity_type: PERSON\n",
      "Average number of annotation: 7.704\n",
      "\n",
      "Average on 586 data in unknown type\n",
      "Methods: inst_expand, entity_type: unknown\n",
      "Average number of annotation: 30.143\n",
      "\n",
      "Average on 169 data in CARDINAL type\n",
      "Methods: inst_expand, entity_type: CARDINAL\n",
      "Average number of annotation: 6.686\n",
      "\n",
      "Average on 185 data in others type\n",
      "Methods: inst_expand, entity_type: others\n",
      "Average number of annotation: 4.081\n",
      "\n",
      "Average on 288 data in GPE type\n",
      "Methods: inst_expand, entity_type: GPE\n",
      "Average number of annotation: 9.868\n",
      "\n",
      "Average on 198 data in ORG type\n",
      "Methods: inst_expand, entity_type: ORG\n",
      "Average number of annotation: 8.273\n",
      "\n",
      "Average on 499 data in DATE type\n",
      "Methods: inst_expand, entity_type: DATE\n",
      "Average number of annotation: 15.110\n",
      "\n",
      "Average on 13 data in ORDINAL type\n",
      "Methods: inst_expand, entity_type: ORDINAL\n",
      "Average number of annotation: 9.000\n",
      "\n",
      "Average on 19 data in QUANTITY type\n",
      "Methods: inst_expand, entity_type: QUANTITY\n",
      "Average number of annotation: 15.895\n",
      "\n",
      "Average on 11 data in MONEY type\n",
      "Methods: inst_expand, entity_type: MONEY\n",
      "Average number of annotation: 4.545\n",
      "\n",
      "Average on 10 data in PERCENT type\n",
      "Methods: inst_expand, entity_type: PERCENT\n",
      "Average number of annotation: 5.100\n",
      "\n",
      "Average on 7 data in TIME type\n",
      "Methods: inst_expand, entity_type: TIME\n",
      "Average number of annotation: 6.286\n",
      "\n",
      "Result using methods inst_expand\n",
      "13.28046357615894\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for met in methods:\n",
    "    print('Result using: ', met)\n",
    "    met_ans=0\n",
    "    met_num=0\n",
    "    \n",
    "    for key in ent_set.keys():\n",
    "        ent_ans=0\n",
    "        ent_num=0\n",
    "        for d in ent_set[key]:\n",
    "            ent_num+=1\n",
    "            ent_ans+=len(d[met])\n",
    "        print('Average on {} data in {} type'.format(ent_num,key))\n",
    "        print('Methods: {}, entity_type: {}'.format(met, key))\n",
    "        print('Average number of annotation: %5.3f'%(ent_ans/ent_num))\n",
    "        print()\n",
    "        \n",
    "        met_ans+=ent_ans\n",
    "        met_num+=ent_num\n",
    "    \n",
    "    print('Result using methods {}'.format(met))\n",
    "    print(met_ans/met_num)\n",
    "    print()\n",
    "    print('--------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f16566b",
   "metadata": {},
   "source": [
    "### TQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fec89b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_set=defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e038ddf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in tq:\n",
    "    if d['ans_type'] in others:\n",
    "        ent_set['others'].append(d)\n",
    "    else:\n",
    "        ent_set[d['ans_type']].append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ed918b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods=['golden_answer', 'fb', 'wiki', 'inst_expand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9fdb2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result using:  golden_answer\n",
      "Average on 744 data in PERSON type\n",
      "Methods: golden_answer, entity_type: PERSON\n",
      "Average number of annotation: 1.000\n",
      "\n",
      "Average on 157 data in others type\n",
      "Methods: golden_answer, entity_type: others\n",
      "Average number of annotation: 1.000\n",
      "\n",
      "Average on 380 data in ORG type\n",
      "Methods: golden_answer, entity_type: ORG\n",
      "Average number of annotation: 1.000\n",
      "\n",
      "Average on 296 data in GPE type\n",
      "Methods: golden_answer, entity_type: GPE\n",
      "Average number of annotation: 1.000\n",
      "\n",
      "Average on 189 data in unknown type\n",
      "Methods: golden_answer, entity_type: unknown\n",
      "Average number of annotation: 1.000\n",
      "\n",
      "Average on 52 data in DATE type\n",
      "Methods: golden_answer, entity_type: DATE\n",
      "Average number of annotation: 1.000\n",
      "\n",
      "Average on 105 data in CARDINAL type\n",
      "Methods: golden_answer, entity_type: CARDINAL\n",
      "Average number of annotation: 1.000\n",
      "\n",
      "Average on 4 data in MONEY type\n",
      "Methods: golden_answer, entity_type: MONEY\n",
      "Average number of annotation: 1.000\n",
      "\n",
      "Average on 5 data in TIME type\n",
      "Methods: golden_answer, entity_type: TIME\n",
      "Average number of annotation: 1.000\n",
      "\n",
      "Average on 2 data in PERCENT type\n",
      "Methods: golden_answer, entity_type: PERCENT\n",
      "Average number of annotation: 1.000\n",
      "\n",
      "Average on 3 data in ORDINAL type\n",
      "Methods: golden_answer, entity_type: ORDINAL\n",
      "Average number of annotation: 1.000\n",
      "\n",
      "Average on 1 data in QUANTITY type\n",
      "Methods: golden_answer, entity_type: QUANTITY\n",
      "Average number of annotation: 1.000\n",
      "\n",
      "Result using methods golden_answer\n",
      "1.0\n",
      "\n",
      "--------------------\n",
      "Result using:  fb\n",
      "Average on 744 data in PERSON type\n",
      "Methods: fb, entity_type: PERSON\n",
      "Average number of annotation: 12.868\n",
      "\n",
      "Average on 157 data in others type\n",
      "Methods: fb, entity_type: others\n",
      "Average number of annotation: 12.892\n",
      "\n",
      "Average on 380 data in ORG type\n",
      "Methods: fb, entity_type: ORG\n",
      "Average number of annotation: 18.250\n",
      "\n",
      "Average on 296 data in GPE type\n",
      "Methods: fb, entity_type: GPE\n",
      "Average number of annotation: 18.186\n",
      "\n",
      "Average on 189 data in unknown type\n",
      "Methods: fb, entity_type: unknown\n",
      "Average number of annotation: 10.222\n",
      "\n",
      "Average on 52 data in DATE type\n",
      "Methods: fb, entity_type: DATE\n",
      "Average number of annotation: 9.327\n",
      "\n",
      "Average on 105 data in CARDINAL type\n",
      "Methods: fb, entity_type: CARDINAL\n",
      "Average number of annotation: 22.190\n",
      "\n",
      "Average on 4 data in MONEY type\n",
      "Methods: fb, entity_type: MONEY\n",
      "Average number of annotation: 3.500\n",
      "\n",
      "Average on 5 data in TIME type\n",
      "Methods: fb, entity_type: TIME\n",
      "Average number of annotation: 26.800\n",
      "\n",
      "Average on 2 data in PERCENT type\n",
      "Methods: fb, entity_type: PERCENT\n",
      "Average number of annotation: 23.000\n",
      "\n",
      "Average on 3 data in ORDINAL type\n",
      "Methods: fb, entity_type: ORDINAL\n",
      "Average number of annotation: 2.333\n",
      "\n",
      "Average on 1 data in QUANTITY type\n",
      "Methods: fb, entity_type: QUANTITY\n",
      "Average number of annotation: 1.000\n",
      "\n",
      "Result using methods fb\n",
      "14.89422084623323\n",
      "\n",
      "--------------------\n",
      "Result using:  wiki\n",
      "Average on 744 data in PERSON type\n",
      "Methods: wiki, entity_type: PERSON\n",
      "Average number of annotation: 13.391\n",
      "\n",
      "Average on 157 data in others type\n",
      "Methods: wiki, entity_type: others\n",
      "Average number of annotation: 13.083\n",
      "\n",
      "Average on 380 data in ORG type\n",
      "Methods: wiki, entity_type: ORG\n",
      "Average number of annotation: 14.703\n",
      "\n",
      "Average on 296 data in GPE type\n",
      "Methods: wiki, entity_type: GPE\n",
      "Average number of annotation: 27.280\n",
      "\n",
      "Average on 189 data in unknown type\n",
      "Methods: wiki, entity_type: unknown\n",
      "Average number of annotation: 3.460\n",
      "\n",
      "Average on 52 data in DATE type\n",
      "Methods: wiki, entity_type: DATE\n",
      "Average number of annotation: 6.654\n",
      "\n",
      "Average on 105 data in CARDINAL type\n",
      "Methods: wiki, entity_type: CARDINAL\n",
      "Average number of annotation: 5.943\n",
      "\n",
      "Average on 4 data in MONEY type\n",
      "Methods: wiki, entity_type: MONEY\n",
      "Average number of annotation: 1.750\n",
      "\n",
      "Average on 5 data in TIME type\n",
      "Methods: wiki, entity_type: TIME\n",
      "Average number of annotation: 12.600\n",
      "\n",
      "Average on 2 data in PERCENT type\n",
      "Methods: wiki, entity_type: PERCENT\n",
      "Average number of annotation: 3.000\n",
      "\n",
      "Average on 3 data in ORDINAL type\n",
      "Methods: wiki, entity_type: ORDINAL\n",
      "Average number of annotation: 9.333\n",
      "\n",
      "Average on 1 data in QUANTITY type\n",
      "Methods: wiki, entity_type: QUANTITY\n",
      "Average number of annotation: 1.000\n",
      "\n",
      "Result using methods wiki\n",
      "14.142414860681114\n",
      "\n",
      "--------------------\n",
      "Result using:  inst_expand\n",
      "Average on 744 data in PERSON type\n",
      "Methods: inst_expand, entity_type: PERSON\n",
      "Average number of annotation: 5.531\n",
      "\n",
      "Average on 157 data in others type\n",
      "Methods: inst_expand, entity_type: others\n",
      "Average number of annotation: 2.038\n",
      "\n",
      "Average on 380 data in ORG type\n",
      "Methods: inst_expand, entity_type: ORG\n",
      "Average number of annotation: 2.405\n",
      "\n",
      "Average on 296 data in GPE type\n",
      "Methods: inst_expand, entity_type: GPE\n",
      "Average number of annotation: 3.179\n",
      "\n",
      "Average on 189 data in unknown type\n",
      "Methods: inst_expand, entity_type: unknown\n",
      "Average number of annotation: 14.735\n",
      "\n",
      "Average on 52 data in DATE type\n",
      "Methods: inst_expand, entity_type: DATE\n",
      "Average number of annotation: 8.923\n",
      "\n",
      "Average on 105 data in CARDINAL type\n",
      "Methods: inst_expand, entity_type: CARDINAL\n",
      "Average number of annotation: 4.314\n",
      "\n",
      "Average on 4 data in MONEY type\n",
      "Methods: inst_expand, entity_type: MONEY\n",
      "Average number of annotation: 4.250\n",
      "\n",
      "Average on 5 data in TIME type\n",
      "Methods: inst_expand, entity_type: TIME\n",
      "Average number of annotation: 4.800\n",
      "\n",
      "Average on 2 data in PERCENT type\n",
      "Methods: inst_expand, entity_type: PERCENT\n",
      "Average number of annotation: 5.000\n",
      "\n",
      "Average on 3 data in ORDINAL type\n",
      "Methods: inst_expand, entity_type: ORDINAL\n",
      "Average number of annotation: 5.000\n",
      "\n",
      "Average on 1 data in QUANTITY type\n",
      "Methods: inst_expand, entity_type: QUANTITY\n",
      "Average number of annotation: 6.000\n",
      "\n",
      "Result using methods inst_expand\n",
      "5.192982456140351\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for met in methods:\n",
    "    print('Result using: ', met)\n",
    "    met_ans=0\n",
    "    met_num=0\n",
    "    \n",
    "    for key in ent_set.keys():\n",
    "        ent_ans=0\n",
    "        ent_num=0\n",
    "        for d in ent_set[key]:\n",
    "            ent_num+=1\n",
    "            ent_ans+=len(d[met])\n",
    "        print('Average on {} data in {} type'.format(ent_num,key))\n",
    "        print('Methods: {}, entity_type: {}'.format(met, key))\n",
    "        print('Average number of annotation: %5.3f'%(ent_ans/ent_num))\n",
    "        print()\n",
    "        \n",
    "        met_ans+=ent_ans\n",
    "        met_num+=ent_num\n",
    "    \n",
    "    print('Result using methods {}'.format(met))\n",
    "    print(met_ans/met_num)\n",
    "    print()\n",
    "    print('--------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50e0e596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSON 744\n",
      "others 157\n",
      "ORG 380\n",
      "GPE 296\n",
      "unknown 189\n",
      "DATE 52\n",
      "CARDINAL 105\n",
      "MONEY 4\n",
      "TIME 5\n",
      "PERCENT 2\n",
      "ORDINAL 3\n",
      "QUANTITY 1\n"
     ]
    }
   ],
   "source": [
    "for k in ent_set.keys():\n",
    "    print(k, len(ent_set[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5421aff",
   "metadata": {},
   "source": [
    "### Error case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5691a042",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/donaldo9603/workspace/numeric/data/evouna/few_shot/1130NQ_train_expansion.json') as f:\n",
    "    few=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "45076417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'exact_match',\n",
       "  'question': \"ranking of st john's medical college bangalore\",\n",
       "  'gold_ans': ['14th'],\n",
       "  'ans_type': 'ORDINAL',\n",
       "  'posneg': 'pos',\n",
       "  'cand_ans_sent': \"The ranking of St John's medical college Bangalore is the 14th.\",\n",
       "  'cand_ans_short': '14th',\n",
       "  'explanation': 'The candidate answer includes the term 14th, which is exactly same with one of the golden answer. So the answer is Yes.',\n",
       "  'expand': ['14th', 'fourteenth']},\n",
       " {'type': 'string_conversion',\n",
       "  'question': 'which is the last season of game of thrones',\n",
       "  'gold_ans': ['The eighth'],\n",
       "  'ans_type': 'ORDINAL',\n",
       "  'posneg': 'neg',\n",
       "  'cand_ans_sent': 'The last season of Game of Thrones is 7th.',\n",
       "  'cand_ans_short': '7th',\n",
       "  'explanation': 'The candidate answer does not include any of the golden answer. So the answer is No.',\n",
       "  'expand': ['The eighth', 'eighth', 'eighth season', '8th', '8th season']},\n",
       " {'type': 'string_conversion',\n",
       "  'question': 'when do the premier league teams enter the league cup',\n",
       "  'gold_ans': ['second round'],\n",
       "  'ans_type': 'ORDINAL',\n",
       "  'posneg': 'pos',\n",
       "  'cand_ans_sent': 'The Premier league teams enter the league cup in the 2nd round.',\n",
       "  'cand_ans_short': '2nd round',\n",
       "  'explanation': 'The candidate answer includes the term 2nd round, which is equivalent with one of the golden answer. So the answer is Yes.',\n",
       "  'expand': ['second round', 'second', '2nd', '2nd round', 'in 2nd round']},\n",
       " {'type': 'exact_match',\n",
       "  'question': 'what rank is a tsgt in the air force',\n",
       "  'gold_ans': ['sixth enlisted rank'],\n",
       "  'ans_type': 'ORDINAL',\n",
       "  'posneg': 'neg',\n",
       "  'cand_ans_sent': 'TSGT is fifth rank in the Air force.',\n",
       "  'cand_ans_short': 'fifth rank',\n",
       "  'explanation': 'The candidate answer does not include any of the golden answer. So the answer is No.',\n",
       "  'expand': ['sixth enlisted rank', 'sixth', 'sixth rank', '6th', '6th rank']},\n",
       " {'type': 'string_conversion',\n",
       "  'question': 'what season of the vampire diaries did the originals start',\n",
       "  'gold_ans': ['fifth'],\n",
       "  'ans_type': 'ORDINAL',\n",
       "  'posneg': 'pos',\n",
       "  'cand_ans_sent': 'Vampire diaries originals started in the 5th season.',\n",
       "  'cand_ans_short': '5th season',\n",
       "  'explanation': 'The candidate answer includes the term 5th, which is equivalent with one of the golden answer. So the answer is Yes.',\n",
       "  'expand': ['fifth',\n",
       "   '5th',\n",
       "   '5th season',\n",
       "   'in 5th season',\n",
       "   'in fifth season',\n",
       "   'fifth season']},\n",
       " {'type': 'exact_match',\n",
       "  'question': 'where did lucy jones come in the eurovision 2017',\n",
       "  'gold_ans': ['15th place'],\n",
       "  'ans_type': 'ORDINAL',\n",
       "  'posneg': 'neg',\n",
       "  'cand_ans_sent': 'Lucy Jones was 11st place in the Eurovision 2017.',\n",
       "  'cand_ans_short': '11st',\n",
       "  'explanation': 'The candidate answer does not include any of the golden answer. So the answer is No.',\n",
       "  'expand': ['15th place', '15th', 'fifteenth', 'fifteenth place']},\n",
       " {'type': 'exact_match',\n",
       "  'question': 'when did forrest gump win the academy award for best picture',\n",
       "  'gold_ans': ['67th Academy Awards'],\n",
       "  'ans_type': 'ORDINAL',\n",
       "  'posneg': 'pos',\n",
       "  'cand_ans_sent': 'Forrest Gump won the best picture award in the 67th Academy Awards.',\n",
       "  'cand_ans_short': '67th Academy Awards',\n",
       "  'explanation': 'The candidate answer includes the term 67th Academy Awards, which is exactly same with one of the golden answer. So the answer is Yes.',\n",
       "  'expand': ['67th Academy Awards',\n",
       "   '67th',\n",
       "   'in 67th Academy Awards',\n",
       "   'sixty-seventh']},\n",
       " {'type': 'string_conversion',\n",
       "  'question': \"what season does mark sloan die in grey's anatomy\",\n",
       "  'gold_ans': ['ninth'],\n",
       "  'ans_type': 'ORDINAL',\n",
       "  'posneg': 'neg',\n",
       "  'cand_ans_sent': \"Mark Sloan died in the 8th season of Grey's Anatomy.\",\n",
       "  'cand_ans_short': '8th',\n",
       "  'explanation': 'The candidate answer does not include any of the golden answer. So the answer is No.',\n",
       "  'expand': ['ninth',\n",
       "   '9th',\n",
       "   '9th season',\n",
       "   'in 9th season',\n",
       "   'in ninth season',\n",
       "   'ninth season']},\n",
       " {'question': 'what pick was peyton manning in the draft',\n",
       "  'gold_ans': ['First selection'],\n",
       "  'ans_type': 'ORDINAL',\n",
       "  'cand_ans_sent': 'Peyton Manning was the 1st selection in the draft.',\n",
       "  'cand_ans_short': '1st',\n",
       "  'posneg': 'pos',\n",
       "  'type': 'string_conversion',\n",
       "  'explanation': 'The candidate answer includes the term 1st selection, which is equivalent with one of the golden answer. So the answer is Yes.'},\n",
       " {'ans_type': 'ORDINAL',\n",
       "  'question': 'what place did fifth harmony get on the x factor',\n",
       "  'gold_ans': ['third place'],\n",
       "  'cand_ans_sent': 'The Fift Harmony get fifth place on the x factor.',\n",
       "  'cand_ans_short': 'fifth',\n",
       "  'posneg': 'neg',\n",
       "  'type': 'exact_match',\n",
       "  'explanation': 'The candidate answer does not include any of the golden answer. So the answer is No.'},\n",
       " {'ans_type': 'ORDINAL',\n",
       "  'question': 'when did gone with the wind received ten academy awards',\n",
       "  'gold_ans': ['the 12th Academy Awards'],\n",
       "  'cand_ans_sent': 'Gone with the wind received ten academy awards in the 12th Academy Awards.',\n",
       "  'cand_ans_short': '12th Academy Awards',\n",
       "  'posneg': 'pos',\n",
       "  'type': 'exact_match',\n",
       "  'explanation': 'The candidate answer includes the term 12th Academy Awards, which is exactly same with one of the golden answer. So the answer is Yes.'},\n",
       " {'ans_type': 'ORDINAL',\n",
       "  'question': 'what was the last season of once upon a time',\n",
       "  'gold_ans': ['The seventh season'],\n",
       "  'cand_ans_sent': 'The last season of Once Upon a time was 5th season.',\n",
       "  'cand_ans_short': '5th season',\n",
       "  'posneg': 'neg',\n",
       "  'type': 'string_conversion',\n",
       "  'explanation': 'The candidate answer does not include any of the golden answer. So the answer is No.'},\n",
       " {'ans_type': 'ORDINAL',\n",
       "  'question': 'what number state is west virginia to enter the union',\n",
       "  'gold_ans': ['35th'],\n",
       "  'cand_ans_sent': 'West Virginia entered the union in the 35th.',\n",
       "  'cand_ans_short': '35th',\n",
       "  'posneg': 'pos',\n",
       "  'type': 'exact_match',\n",
       "  'explanation': 'The candidate answer includes the term 35th, which is exactly same with one of the golden answer. So the answer is Yes.'},\n",
       " {'ans_type': 'ORDINAL',\n",
       "  'question': 'when was aaron rodgers picked in the draft',\n",
       "  'gold_ans': ['24th overall pick'],\n",
       "  'cand_ans_sent': 'Aaron Rodgers was picked 25th overall in the draft.',\n",
       "  'cand_ans_short': '25th',\n",
       "  'posneg': 'neg',\n",
       "  'type': 'exact_match',\n",
       "  'explanation': 'The candidate answer does not include any of the golden answer. So the answer is No.'},\n",
       " {'ans_type': 'ORDINAL',\n",
       "  'question': 'where did brazil finish in 2014 world cup',\n",
       "  'gold_ans': ['fourth place'],\n",
       "  'cand_ans_sent': 'Brazil finised in the 4th place in 2014 World Cup.',\n",
       "  'cand_ans_short': '4th place',\n",
       "  'posneg': 'pos',\n",
       "  'type': 'string_conversion',\n",
       "  'explanation': 'The candidate answer includes the term 4th place, which is equivalent with one of the golden answer. So the answer is Yes.'},\n",
       " {'ans_type': 'ORDINAL',\n",
       "  'question': 'what is indian air force rank in the world',\n",
       "  'gold_ans': ['fourth'],\n",
       "  'cand_ans_sent': 'Indian air force rank is 3rd in the world.',\n",
       "  'cand_ans_short': '3rd',\n",
       "  'posneg': 'neg',\n",
       "  'type': 'string_conversion',\n",
       "  'explanation': 'The candidate answer does not include any of the golden answer. So the answer is No.'}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few['ORDINAL']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f000344a",
   "metadata": {},
   "source": [
    "### TP FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85834cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donaldo9603/.conda/envs/numeric/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/home/donaldo9603/.conda/envs/numeric/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:470: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from eval import metric_max_over_ground_truths, soft_exact_match_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "fe7d91cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dir='/home/donaldo9603/workspace/numeric/gptexpansion/out/49755/TQ_eval.json'\n",
    "data_dir='/home/donaldo9603/workspace/numeric/gptexpansion/out/49754/NQ_eval.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "413109be",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir) as f:\n",
    "    data=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "87ba21c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model='gpt35'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c90814a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original\n",
      "FP: 7\n",
      "FN: 450\n",
      "total acc: 0.849\n",
      "\n",
      "Extension\n",
      "FP: 230\n",
      "FN: 198\n",
      "total acc: 0.858\n"
     ]
    }
   ],
   "source": [
    "orig_fn=0\n",
    "orig_fp=0\n",
    "ext_fn=0\n",
    "ext_fp=0\n",
    "\n",
    "orig_crt=0\n",
    "ext_crt=0\n",
    "\n",
    "turn_wrong=[]\n",
    "turn_right=[]\n",
    "\n",
    "for d in data:\n",
    "    human=1 if d['judge_{}'.format(model)] else 0\n",
    "    orig=metric_max_over_ground_truths(soft_exact_match_score, d['answer_{}'.format(model)], d['golden_answer']) \n",
    "    ext=metric_max_over_ground_truths(soft_exact_match_score, d['answer_{}'.format(model)], d['inst_expand']) \n",
    "    \n",
    "    if orig!=human:\n",
    "        if ext==human:\n",
    "            turn_right.append(d)\n",
    "        if orig==1:\n",
    "            orig_fp+=1\n",
    "        else:\n",
    "            orig_fn+=1\n",
    "    else:\n",
    "        orig_crt+=1\n",
    "    \n",
    "    if ext!=human:\n",
    "        if orig==human:\n",
    "            turn_wrong.append(d)\n",
    "        if ext==1:\n",
    "            ext_fp+=1\n",
    "            \n",
    "        else:\n",
    "            ext_fn+=1\n",
    "    else:\n",
    "        ext_crt+=1\n",
    "\n",
    "print(\"Original\")\n",
    "print('FP: {}'.format(orig_fp))\n",
    "print('FN: {}'.format(orig_fn))\n",
    "print('total acc: %5.3f'%(orig_crt/len(data)))\n",
    "print()\n",
    "print(\"Extension\")\n",
    "print('FP: {}'.format(ext_fp))\n",
    "print('FN: {}'.format(ext_fn))\n",
    "print('total acc: %5.3f'%(ext_crt/len(data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d64924df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252\n",
      "223\n"
     ]
    }
   ],
   "source": [
    "print(len(turn_right))\n",
    "print(len(turn_wrong))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2b12746d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('PERSON', 61), ('unknown', 59), ('DATE', 44), ('GPE', 26), ('ORG', 16), ('CARDINAL', 6), ('NORP', 4), ('WORK_OF_ART', 2), ('LOC', 1), ('QUANTITY', 1), ('PRODUCT', 1), ('FAC', 1), ('TIME', 1)]\n"
     ]
    }
   ],
   "source": [
    "wrong=[]\n",
    "for d in turn_wrong:\n",
    "    wrong.append(d['ans_type'])\n",
    "print(Counter(wrong).most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "11ced728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['question', 'golden_answer', 'answer_fid', 'judge_fid', 'answer_gpt35', 'judge_gpt35', 'answer_chatgpt', 'judge_chatgpt', 'answer_gpt4', 'judge_gpt4', 'answer_newbing', 'judge_newbing', 'improper', 'ans_type', 'fb', 'inst_expand_input', 'inst_expand'])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turn_wrong[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0663b74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in turn_wrong[:10]:\n",
    "    #print(d['question'])\n",
    "    #print(d['golden_answer'])\n",
    "    print(d['inst_expand'])\n",
    "    print(d['ans_type'])\n",
    "    print(d['inst_expand_input'])\n",
    "    #print(d['answer_{}'.format(model)])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "57b96ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c4b5cd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The only Englishman to become Pope was Adrian IV, who was Pope from 1154 to 1159.\n",
      "['Nicholas Breakspear, who was Adrian IV from 1154 to 1159']\n",
      "['Nicholas Breakspear, who was Adrian IV from 1154 to 1159', 'Adrian IV', 'Nicholas Breakspear', 'Adrianus IV', 'Nicholas Breakspear', 'Adrian IV of Rome']\n",
      "\n",
      "The comic strip character \"Bruiser\" was named after heavyweight boxing champion James J. Jeffries.\n",
      "['Jeff, of Mutt and Jeff']\n",
      "['Jeff, of Mutt and Jeff', 'James J. Jeffries', 'Jeffries']\n",
      "\n",
      "The two prime ministers of Britain during World War II were Winston Churchill (1940-1945) and Clement Attlee (1945-1951).\n",
      "['Neville Chamberlain and Winston Churchill']\n",
      "['Neville Chamberlain and Winston Churchill', 'Chamberlain and Churchill', 'Neville Chamberlain', 'Winston Churchill', 'Chamberlain', 'Churchill']\n",
      "\n",
      "In January 2004, Jason Alexander from Louisiana made headlines when he was arrested for allegedly shooting a man in a road rage incident. Alexander was charged with attempted second-degree murder and later pleaded guilty to an amended charge of aggravated battery.\n",
      "['He married Britney Spears']\n",
      "['He married Britney Spears', 'He married Britney Jean Spears', 'Jason Alexander', 'Britney Spears', 'Jason Alexander and Britney Spears']\n",
      "\n",
      "The Canary Islands are named after the canary bird, which is native to the islands.\n",
      "['Dog']\n",
      "['Dog', 'Canary', 'Canary bird']\n",
      "\n",
      "Jupiter. Jupiter has four large moons known as the Galilean moons, named after their discoverer Galileo Galilei. The four moons are Io, Europa, Ganymede, and Callisto. These moons have been given nicknames derived from characters in the works of William Shakespeare: Io is named after the character in Othello, Europa is named after the princess in King Lear, Ganymede is named after the page in As You Like It, and Callisto is named after the nymph in The Winter's Tale.\n",
      "['Uranus']\n",
      "['Uranus', 'William Shakespeare', \"William Shakespeare's planet\", \"Uranus' moons\"]\n",
      "\n",
      "Burnside was a spin off from the Australian series Blue Heelers.\n",
      "['The Bill']\n",
      "['The Bill', 'Blue Heelers', 'Blue Heelers: Burnside', 'Burnside']\n",
      "\n",
      "You are playing a 16-ender, which is the maximum number of ends in a bonspiel.\n",
      "['Curling']\n",
      "['Curling', 'Enders', 'Bonspiel']\n",
      "\n",
      "The GMC Jimmy is a mid-size SUV produced by General Motors.\n",
      "['SUZUKI']\n",
      "['SUZUKI', 'General Motors', 'Suzuki Motor Corporation', 'GM', 'Suzuki Motor Co.', 'Suzuki Motor Company']\n",
      "\n",
      "Leonid Brezhnev succeeded Nikita Kruschev as leader of the Soviet Union in 1964.\n",
      "['ALEXEI KOSYGIN']\n",
      "['ALEXEI KOSYGIN', 'Leonid Brezhnev', 'Leonid Ilyich Brezhnev', 'Leonid I. Brezhnev']\n",
      "\n",
      "The actor who has played James Bond in the most movies is Sean Connery, with seven films.\n",
      "['Roger Moore']\n",
      "['Roger Moore', 'George Lazenby', 'Sean Connery', 'Timothy Dalton', 'Pierce Brosnan', 'Daniel Craig']\n",
      "\n",
      "The Monument is located in Monument Street in the City of London.\n",
      "['Pudding Lane']\n",
      "['Pudding Lane', ' Fish Street Hill', ' Monument Street', ' Monument Lane', ' Monument Road']\n",
      "\n",
      "Venus Williams\n",
      "['Serena Williams']\n",
      "['Serena Williams', 'Williams', 'Serena', 'Serena Jameka Williams']\n",
      "\n",
      "Angelina Jolie is the daughter of actor Jon Voight.\n",
      "['JOHN VOIGHT']\n",
      "['JOHN VOIGHT', 'John Voight', 'Jon Voight', 'Jonathan Vincent Voight']\n",
      "\n",
      "The robot co-pilot of XL5 is named Zoonie the Lazoon.\n",
      "['Robert the Robot']\n",
      "['Robert the Robot', 'Robert', 'Robbie', 'Robot']\n",
      "\n",
      "Jean-Paul Marat was a physician and political theorist.\n",
      "['Journalist']\n",
      "['Journalist', 'Physician', 'Doctor', 'Revolutionary']\n",
      "\n",
      "A cargo ship would have carried these items.\n",
      "['\"A DIRTY BRITISH COASTER (in John Masefield\\'s \"\"Cargoes\"\")\"']\n",
      "['\"A DIRTY BRITISH COASTER (in John Masefield\\'s \"\"Cargoes\"\")\"', 'British coaster', 'Coaster', 'Ship']\n",
      "\n",
      "?\n",
      "\n",
      "Dame Edna Everage is a comedic character created by Australian comedian Barry Humphries. She is a character of a suburban housewife from Melbourne, Australia.\n",
      "['Moony Ponds']\n",
      "['Moony Ponds', ' Moonee Ponds', ' Melbourne', ' Victoria']\n",
      "\n",
      "The engineer with the big triangular hairstyle in the Dilbert cartoons is named Wally.\n",
      "['Alice']\n",
      "['Alice', 'Asok', 'Carol', 'Carol the Secretary', \"Dilbert's Boss\", \"Dilbert's Coworker\", \"Dilbert's Coworkers\", \"Dilbert's Manager\", \"Dilbert's Secretary\", \"Dilbert's Supervisor\", \"Dilbert's Teammate\", \"Dilbert's Teammates\", \"Dilbert's Workmate\", \"Dilbert's Workmates\", 'Dogbert', 'Dogbert the Dog', 'Elbonia', 'Engineer', 'Engineers', 'Janet', 'Jimmy', 'Jimmy the Intern', 'Loud Howard', 'Mordac', 'Mordac the Preventer of Information Services', 'Phil', 'Phil the Prince of Insufficient Light', 'Ratbert', 'Ted', 'Ted the Generic Guy', 'Tina', 'Tina the Tech Writer', 'Wally', 'Wally the Engineer']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fp in fps:\n",
    "    if fp['ans_type']=='PERSON':\n",
    "        print(fp['answer_{}'.format(model)])\n",
    "        print(fp['golden_answer'])\n",
    "        print(fp['inst_expand'])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5440db2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'unknown': 22, 'PERSON': 19, 'ORG': 11, 'GPE': 3, 'NORP': 2, 'PERCENT': 1, 'LOC': 1, 'CARDINAL': 1})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(fp_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20599a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda:.conda-numeric]",
   "language": "python",
   "name": "conda-env-.conda-numeric-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
